---
output:
  word_document: default
  pdf_document:
    includes:
      before_body: title.sty
      number_sections: yes
bibliography: /Users/aleenaalby/Desktop/Diabetic-Retinopathy-detection/Documentation/references.bib
link-citations: yes
header-includes:
- \usepackage{fancyhdr}
- \pagestyle{fancy}
- \thispagestyle{plain}
- \thispagestyle{empty}
- \fancyhead[R]{\textbf{Detection of Diabetic Retinopathy}}
- \fancyhead[L]{Aleena Alby}
- \setlength{\footskip}{30pt}
---

\newpage

**Declaration of Originality**

I declare that this project is all my own work and has not been copied in part or in whole from any other source except where duly acknowledged. As such, all use of previously published work (from books, journals, magazines, internet etc.) has been acknowledged by citation within the main report to an item in the References or Bibliography lists. I also agree that an electronic copy of this project may be stored and used for the purposes of plagiarism prevention and detection.

**Statement of copyright**

I acknowledge that the copyright of this project report, and any product developed as part of the project, belong to Coventry University. Support, including funding, is available to commercialise products and services developed by staff and students. Any revenue that is generated is split with the inventor/s of the product or service. For further information please see [www.coventry.ac.uk/ipr](http://www.coventry.ac.uk/ipr) or contact [ipr\@coventry.ac.uk](mailto:ipr@coventry.ac.uk){.email}.

**Statement of ethical engagement**

I declare that a proposal for this project has been submitted to the Coventry University ethics monitoring website (<https://ethics.coventry.ac.uk/>) and that the application number is listed below (Note: Projects without an ethical application number will be rejected for marking)

Signed: Date:

Please complete all fields.

|                                         |
|:----------------------------------------|
| First Name: Aleena                      |
| Last Name: Alby                         |
| Student ID number                       |
| Ethics Application Number               |
| 1^st^ Supervisor Name Prof James Brusey |
| 2^nd^ Supervisor Name                   |

```{=html}
<!--  **This form must be completed, scanned and included with your project
submission to Turnitin. Failure to append these declarations may result
in your project being rejected for marking.** -->
```
\newpage

# Abstract

We used simple CNN, ResNet50, ResNet101, DenseNet201, VGG19, and EfficientNet in this study.

```{=tex}
\pagebreak
\tableofcontents
\pagebreak
\listoftables
\pagebreak
\listoffigures 
\pagebreak
```
# Introduction

One of the major causes of eye vision loss is diabetes. While delayed examination would have a higher effect on the retinal area of the eye, early detection of diabetes is crucial. The key factors affecting the rise in the occurrence of this disease are people's lifestyles and other contributing factors, and it is anticipated that this trend will continue. According to Tien Y Wong et al, among the 285 million diabetics worldwide, 33 percent of those individuals exhibit DR symptoms[@r2015]. Nearly 90% of individuals can be diagnosed, and long-term effects can be reduced, with thorough screening and regular checkups. Statistics show that the percentage of diabetic patients over the age of 18 has increased from 4.7% to 8.5%. About 61.3 million Indians between the ages of 20 and 79 have been diagnosed as diabetic patients. By 2030, it is predicted that this number would likely rise to 101.2 million [@whiting2011idf].

The retinal blood vessels are harmed by a blood glucose spike.This rise in blood glucose levels primarily damages blood vessels, allowing blood to seep into the eyes and weakening the visual system. The brain activates the neighbouring cells to take control of the situation when it detects a blood leak. This behaviour causes aberrant blood vessel development. Newly created vessels lack strength. In time, they affect the person's vision. Therefore, it is essential that a diabetic patient constantly test routine eye exams. The significant issue here is that DR is primarily an asymptomatic eye condition that does not manifest distinctive symptoms until a late stage is reached. The manual examination of retinal image features is a challenging and taxing task, nevertheless. Many automated diagnostic technologies have been created recently to help ophthalmologists examine retinal abnormalities, which has helped to solve this problem.

![Normal Retina Vs Diabetic Retinopathy Retina [@diabetica]](images/image%201.jpg "Normal Retina Vs Diabetic retinopathy Retina [@diabetica]"){width="400" height="300"}

\newpage

## Background to the Project

Artificial intelligence (AI) will be used more often in the healthcare sector as a result of the complexity and growth of data within the field [@davenport2019]. Numerous studies have proven that AI is capable of doing important healthcare tasks including disease diagnosis as well as or better than humans. Deep learning, or neural network models with many levels of features or variables that predict outcomes, is one of the most difficult types of machine learning.

### Artificial Neural Networks

Artificial neural networks have a structure that is comparable to biological neural networks. The history of neural networking probably began in the late 1800s with the pursuit for scientific understanding of how the human brain worked. In current artificial neural networks, the neuron model McCulloch and Pitts proposed in 1943 is still utilized. The first artificial neural network was developed by Narvin Minsky [@history].

Artificial neural networks use a range of mathematical processing layers to learn the data provided to them. Perceptrons are neural networks with only one layer. The input units (receptor), connection weights, summation function, computation, and output units make up an artificial neuron (effectors). The input layer receives information. The purpose of the neural network is to process or learn from this data. Data enters the input layer and then passes via one or more hidden levels. It is the job of the hidden layers to transform the input such that the output layer can use it. The weights typically represent the strength of the connections between the neurons. The activation function is used to obtain the desired result for the given problem. There are several activation functions, For instance,Â ReLU, linear regression, logistic regression, identity function, binary sigmoid, bipolar sigmoid, bipolar, hyperbolic tangent [@v2021a]. An enormous amount of data, known as a training set, must be provided to ANNs in order for them to learn.

![A neural network with three hidden neurons in one hidden layer and four inputs [@113neu].](images/ann.jpg){width="298"}

According to a study of AI applications in health care, Artificial neural networks have been used in important illness areas like cancer or cardiology etc. Clinical diagnosis, cancer prediction, speech recognition, image analysis, and drug research are examples of uses of ANN in the healthcare industry [@shahid2019].

### Convolutional neural networks (CNN)

Convolutional neural networks, also known as convnets or CNNs. CNN is a powerful and effective image processing algorithm. It is a subset of the feed-forward artificial neural network models that are employed for diverse purposes. In the late 1990s, Bell Labs professor Yann LeCunn developed the first effective convolution networks. Convolutional Neural Networks specialized in image & video recognition applications. CNN is primarily utilised for image analysis applications such segmentation, object detection, and image recognition [@tripathi2021]. It have millions of parameters, a large number of hidden layers, and input and output layers. Prior to applying an activation function, it subsamples the input using convolution and pooling techniques. All of the hidden layers are partially connected , with the completely connected layer at the end resulting in the output layer. All image processing applications, including face and pattern recognition, have shown CNN to be extremely effective. There are numerous architectures used by CNN, including LeNet, AlexNet, GoogleNet, ConvNet, and ResNet.

![Typical CNN architecture [@kumar2022]](images/Typical-CNN-architecture.png){width="470"}

**Convolutional Layer**

Filters are combined to produce convolutional layers, which are then applied to input images. A feature map also known as an activation map, a representation of the input image with the filters applied, is the outcome of the convolutional layer.

![Convolutional Layer - **Source:** [@reynolds]](images/covoltionlayer.png){width="386"}

**Pooling layer**

By pooling layers, the input can be processed more quickly and with less memory use due to its reduced spatial size. Every feature map is handled independently by the pooling layer. Pooling also facilitates a decrease in the number of parameters and accelerates training. Max pooling and average pooling are the two primary types of pooling. While average pooling uses the average value from each feature map, max pooling uses the maximum value.

![Pooling in CNN [@student2018]](images/pooling.png){width="371"}

**Fully connected layer**

The final layer of a convolutional neural network is fully connected layer. Each neuron in a fully connected layer is fully connected to every other neuron in the previous layer. The earlier layer's features map is flattened to a vector. The complicated correlations between high-level features are then captured by feeding this vector into a fully connected layer. The output of this layer is a feature vector with only one dimension [@pokhrel2019].

### Transfer Learning

Transfer learning is the process of applying a previously learned model to a new problem. Transfer learning is the process through which we attempt to apply the knowledge that have gained from one assignment to another in order to better understand the concept. Transfer learning is useful in situations when it is not possible to get the large amounts of data required to train a neural network from scratch.

![Transfer Learning Concept - **Source** [@transfer]](images/Screenshot%202022-12-04%20at%2018.40.00-01.png){width="438"}

Transfer learning can provide an effective machine learning model with relatively minimal training data because the model has already been trained. Additionally, training time is reduced because it can take days to complete a complicated task after creating a deep neural network from scratch [@sharma2021].

## Project Objectives

Convolutional neural networks (CNNs) and a transfer learning model were both used in this study to build an image classification model for diagnosing diabetic retinopathy. The following objectives are considered at every stage of the modelling process:

1.  Review existing classification methods and publications.

2.  Obtain the required dataset.

3.  Create a classification model using transfer learning and CNN.

4.  Evaluate the performance of the models.

## Overview of This Report

\newpage

# Literature Review

In recent years, numerous deep learning based automatic DR detection systems have emerged. In this section, some of the recent research projects have been addressed.

A technique for recognising diabetic retinopathy based on transfer learning is proposed by Yuchen Wu et.al [@8725801]. They used data from the official Kaggle website, then they conduct data amplification, data flipping, data folding, and contrast adjusting. Then, use pretrained model such as VGG19, InceptionV3, Resnet50, etc. They oversample the data category with a small number due to the severely unbalanced data. The performance of VGG19 was 51 % accuracy and Resnet50 was 49% InceptionV3 performed better than other models with classification accuracy of 60%.

Using transfer learning, Esra Kaya and Ismail Saritas created CNN for the identification of diabetic retinopathy [@9828576]. To find the best effective architecture, photographs from the DRIVE (Digital Retinal Images for Vessel Extraction) dataset of DR patients and healthy people were classified using Convolutional Neural Network (CNN) architectures as a transfer learning technique. They utilised contrast-limited adaptive histogram equalisation to improve the clarity of the image. They assessed the ResNet18, GoogleNet, and SqueezeNet CNN architectures' performances as feature extraction techniques and classifiers. For ResNet18 and squuezeNet, they employed adam optimizer, while for googleNet, they used sgdm. There are 71 layers in ResNet18, 144 layers in GoogleNet, and 68 layers in SqueezeNet. ResNet18 was discovered to be the most effective architecture as a classifier with 100% accuracy.

Fundus images from the Kaggle opensource dataset were used by Nikhil Sathya Kumar and Dr. B. Ramaswamy Karthikeyan to identify DR using CNNs, Transformers, and MLPs [@9651024]. The dataset includes more than 3600 photographs with a resolution of 2416\*1736. ResNet and EfficientNet based on CNN, Vision-Transformer and SwinTransformer based on Transformer, and MLP-Mixer based on MLP architecture were the models chosen for this study.The findings show that, in comparison to CNN and MLP based models, Transformer based models were more accurate. All models underwent 15 epochs of training. The most accurate Transformer-based model was Swin with 92.49% accuracy.

ImageNet model was proposed by Jayakumari.C et.al [@9215270]. Here the TensorFlow framework is used to build a convolutional neural network model in Python. The size of each image has been reduced to 224 X 224 X 3. The dataset is under-sampled here because to the imbalance in the dataset. Additionally, to improve accuracy, the classes were reduced from 5 to 2. The model trained the network using the Adam optimizerÂ and categorical cross-entropyÂ as a loss function. The model was executed 100 epochs. The model accuracy in training was 98.8%, and in validation accuracy was 98.5%.

A CNN method was suggested by Frans Coenen et.al to diagnose DR with a sensitivity of 95 % and accuracy of 75% [@pratt2016convolutional].They train the network using a high-end graphics processor unit (GPU) on the publicly available Kaggle dataset.

Pathak et.al classified early-stage DR using a deep learning method [@9432312]. They have employed a variety of classifier-based techniques, including SVM (Support Vector Machine), CNN (Convolution Neural Network), DCNN (Deep Convolution Neural Network), ANN (Artificial Neural Network), NB (Naive Bayes), and threshold-based strategies. The model achieved 90% accuracy for the SVM, 91% for the ANN, 92.9% for the NB, 97% for the Thresholding-Based, and 96.5% for the DCNN. They concluded that the DCNN technique is highly accurate and productive.

\newpage

+----------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------+
| **Methods & Ref**                                                                                                                            | **Datasets Used**                                                                                              | **Techniques**                                                                                                                                                                                                                                                                      | **Performance metrics**                                                                                                        |
+==============================================================================================================================================+:===============================================================================================================+=====================================================================================================================================================================================================================================================================================+================================================================================================================================+
| **Transfer Learning models** [@8725801]                                                                                                      | Kaggle Dataset                                                                                                 | VGG19, InceptionV3, Resnet50                                                                                                                                                                                                                                                        | VGG19 - 51%, InceptionV3 - 60%, Resnet50 - 49%                                                                                 |
+----------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------+
|                                                                                                                                              |                                                                                                                |                                                                                                                                                                                                                                                                                     |                                                                                                                                |
+----------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------+
| **CNN** [@9828576]                                                                                                                           | DRIVE dataset (40 images in the database were chosen randomly from 400 images)                                 | They assessed the ResNet18, GoogleNet, and SqueezeNet                                                                                                                                                                                                                               | ResNet18 - 100 %, GoogleNet - 68.2 %, SqueezeNet - 67.4 %                                                                      |
+----------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------+
|                                                                                                                                              |                                                                                                                |                                                                                                                                                                                                                                                                                     |                                                                                                                                |
+----------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------+
| **CNN**, **MLP & Transfomer** [@9651024]                                                                                                     | Aptos dataset from Kaggle (6590 Images)                                                                        | EfficientNet, ResNet, MLP-Mixer, ViT , ViT+MLP, Swin and Swin+ViT                                                                                                                                                                                                                   | EfficientNet -91.18 %, ResNet - 89.63%, MLP-Mixer - 94.47%, ViT - 91.13 %, ViT+MLP - 89.73%, Swin - 92.49%, Swin+ViT - 91.91 % |
+----------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------+
|                                                                                                                                              |                                                                                                                |                                                                                                                                                                                                                                                                                     |                                                                                                                                |
+----------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------+
| **ImageNet** [@9215270]                                                                                                                      | Kaggle Dataset                                                                                                 | ImageNet                                                                                                                                                                                                                                                                            | 98.6%                                                                                                                          |
+----------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------+
|                                                                                                                                              |                                                                                                                |                                                                                                                                                                                                                                                                                     |                                                                                                                                |
+----------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------+
| **CNN** [@pratt2016convolutional]                                                                                                            | Kaggle Dataset                                                                                                 | CNN                                                                                                                                                                                                                                                                                 | 75%                                                                                                                            |
|                                                                                                                                              |                                                                                                                |                                                                                                                                                                                                                                                                                     |                                                                                                                                |
|                                                                                                                                              | (80,000 Images)                                                                                                |                                                                                                                                                                                                                                                                                     |                                                                                                                                |
+----------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------+
|                                                                                                                                              |                                                                                                                |                                                                                                                                                                                                                                                                                     |                                                                                                                                |
+----------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------+
| **SVM classifier-Based technique, CNN classifier, DCNN classifier, ANN classifier, NB classifier, Thresholding Based techniques**.[@9432312] | Indian Diabetic Retinopathy Image Dataset (IDRiD), High-Resolution Fundus (HRF) Image Database, Kaggle dataset | Using a classifier-based SVM (Support Vector Machine) method, Convolution neural network classifiers,Â  DCNN (deep convolution neural network)Â classifiers, artificial neural network classifiers, naive bayes classifiers, and threshold-based methods are examples of classifiers. | SVM - 90%                                                                                                                      |
|                                                                                                                                              |                                                                                                                |                                                                                                                                                                                                                                                                                     |                                                                                                                                |
|                                                                                                                                              |                                                                                                                |                                                                                                                                                                                                                                                                                     | CNN - Best                                                                                                                     |
|                                                                                                                                              |                                                                                                                |                                                                                                                                                                                                                                                                                     |                                                                                                                                |
|                                                                                                                                              |                                                                                                                |                                                                                                                                                                                                                                                                                     | ANN - 91%                                                                                                                      |
|                                                                                                                                              |                                                                                                                |                                                                                                                                                                                                                                                                                     |                                                                                                                                |
|                                                                                                                                              |                                                                                                                |                                                                                                                                                                                                                                                                                     | NB - 92.6%                                                                                                                     |
|                                                                                                                                              |                                                                                                                |                                                                                                                                                                                                                                                                                     |                                                                                                                                |
|                                                                                                                                              |                                                                                                                |                                                                                                                                                                                                                                                                                     | Thresholding Based -97%                                                                                                        |
|                                                                                                                                              |                                                                                                                |                                                                                                                                                                                                                                                                                     |                                                                                                                                |
|                                                                                                                                              |                                                                                                                |                                                                                                                                                                                                                                                                                     | DCNN - 96.5%                                                                                                                   |
+----------------------------------------------------------------------------------------------------------------------------------------------+----------------------------------------------------------------------------------------------------------------+-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------+--------------------------------------------------------------------------------------------------------------------------------+

: DR detection methods

\pagebreak

# Methodology

The software development life cycle involves using common business procedures for creating software applications. After carefully examining a few well-known models, including Waterfall, Iterative, V-Model, and Agile approach, I have chosen to adopt the Agile model in this study.

**Agile Methodology**

Agile is a method of software development that aims to provide functional software consistently through rapidÂ iterations [@whatis]. An agile methodology emphasizes a cooperative, iterative, and incremental approach to project management.

1.  **Better quality**

2.  **Speed and flexibility**

3.  **cost management**

    The team consider the budget when making decisions after each stage.This is a crucial component of project management since it enables teams to comprehend the expenses associated with each feature, which will be taken into consideration when making strategic decisions.

4.  **Project's progress is fully visible and updated in real-time**

5.  **stakeholders' participation**

## *Data pre-processing*

Image pre-processing was performed with the aim to decrease unclear image and reduce image size. The plot below illustrates the class imbalance in the original dataset.

![Initial data distribution](images/LevelsOfDR.png){width="343"}

The dataset consist of 35,126 set of images. The orginal image have 1944 \* 2592 \* 3 size, and all images are jpeg format. The classes have an uneven distribution of images. In the Figure above, the precise distribution is displayed.

1.  Image Resizing

    Due to the enormous size of the dataset, it was drastically downsized before being sent to the network. Each input image is 256 \* 256 in size after resizing.

2.  Removing Unclear Image

    Some images have a blackish or white tint. Because it might affect the outcome, this type of image cannot be fed into the network. The removal of an unclear image is a crucial step that must be taken.

![A sample retinal image frame with and without DR](images/Screenshot%202022-11-26%20at%2014.24.48.png){width="289"}

**Data augmentation**

One of the regularisation strategies is data augmentation. Regulating data aims to prevent the developed model from being overfit. Data augmentation is a method of manipulating data without distorting its core or essence.

**Contrast Limited Adaptive Histogram Equalization (CLAHE ) Approach**

Adaptive histogram equalisation has a variation known as Contrast Limited Adaptive Histogram Equalization. CLAHE performs contrast limiting and high precision histogram equalisation in small patches or tiles [@senaratne2020]. Instead of processing the entire image, CLAHE works with discrete sections of it called tiles. The false borders are then eliminated by combining the adjacent tiles using bilinear interpolation. To enhance the contrast of photographs, this method is used.

![Before CLAHE\
](images/Screenshot%202022-11-26%20at%2014.24.48-01.png){width="251" height="60"}

![After CLAHE](images/Screenshot%202022-12-01%20at%2020.26.17-01.png){width="248"}

**Under-Sampling**

In order to balance the class distribution for a classification dataset with a skewed class distribution, a procedures known as under-sampling has been used. One or more classes (the minority classes) will have few examples, while one or more classes (the majority classes) will have many instances (the majority classes). Here, we can observe that the class with the label "no DR" has the most images. This will impact the experiment's outcome. The quality of the data is directly correlated with the quality of the model. The approach taken in this study is to "undersample" the data category with a large number in the original data set.

To obtain good accuracy for training, the images have been categorised into two groups since the Dataset primarily contains images from the No DR category and contains few images from other categories.

![Data Distribution after under-sampling](images/Screenshot%202022-12-02%20at%2016.30.33.png){width="298"}

| **Type of Diabetics Diagnosis** | **No. of Images** |
|---------------------------------|-------------------|
| With DR                         | 5152              |
| Without DR                      | 5152              |
| **Total**                       | **10304**         |

: Diabetic Retinopathy Dataset

\pagebreak

# Requirements

In this section, I described the steps necessary to finish this research paper. I preferred the agile development methodology outlined in section 3. Since it allows us to change the requirements in accordance to how the project is evolving.

## Dataset

Finding the appropriate dataset is essential for the creation of a best model. This study using dataset available at Kaggle[@diabetica_data]. This Retinal images were provided by EyePACS. The dataset containing large set of high-resolution retina images taken under a variety of imaging conditions. For each image, a left and right field is provided. Images are identified by a image id and either the left or right eye (for example, 1 left.jpeg represents the patient number 1's left eye).

+----------------+-----------+-----------------------------------------------------------------------------------------------------------------------------------+
| **DR classes** | **Level** | **Description**                                                                                                                   |
+================+===========+===================================================================================================================================+
| No DR          | 0         | Healthy Retina (Normal)                                                                                                           |
+----------------+-----------+-----------------------------------------------------------------------------------------------------------------------------------+
|                |           |                                                                                                                                   |
+----------------+-----------+-----------------------------------------------------------------------------------------------------------------------------------+
| Mild           | 1         | Retina with tiny bulges (microaneurysms)                                                                                          |
+----------------+-----------+-----------------------------------------------------------------------------------------------------------------------------------+
|                |           |                                                                                                                                   |
+----------------+-----------+-----------------------------------------------------------------------------------------------------------------------------------+
| Moderate       | 2         | Retina with microaneurysms, higher risk of developing vision problems in the future                                               |
+----------------+-----------+-----------------------------------------------------------------------------------------------------------------------------------+
|                |           |                                                                                                                                   |
+----------------+-----------+-----------------------------------------------------------------------------------------------------------------------------------+
| Severe         | 3         | Retina with severe and widespread microaneurysms, including bleeding into the retina                                              |
+----------------+-----------+-----------------------------------------------------------------------------------------------------------------------------------+
|                |           |                                                                                                                                   |
+----------------+-----------+-----------------------------------------------------------------------------------------------------------------------------------+
| Proliferative  | 4         | New blood vessels and scar tissue have formed on your retina, which can cause significant bleeding and lead toÂ retinal detachment |
+----------------+-----------+-----------------------------------------------------------------------------------------------------------------------------------+

: [@diabetic2017]

![Dataset](images/Screenshot%202022-12-04%20at%2019.19.55.png){width="269"}

## Skill Requirements

We need to acquire a few specific deep learning related skills before we can begin our research project.

-   Python

-   Probability

-   Keras

-   Tensorflow

-   Computer Science Fundamentals and Programming.

-   Machine Learning Knowledge.

-   Knowledge of Deep Learning Algorithms.

-   Knowledge of Deep Learning Frameworks.

## System Requirements

+--------------------+---------------+
| System Type        | 64 bit        |
+--------------------+---------------+
| OS Name            | Mac os mojave |
+--------------------+---------------+
| Processor          | Intel Core i5 |
+--------------------+---------------+
| Installed Physical | 8 GB          |
|                    |               |
| Memory (RAM)       |               |
+--------------------+---------------+

: System Configuration

\newpage

# Analysis

\newpage

# Design

This section reviews numerous approaches and methods for various classifiers namely CNN, ResNet50, VGG19, DenseNet201 and EfficientNet V2L.

.

***ResNet architecture***

In the community of computer vision and deep learning during the past few years, ResNet was undoubtedly the most revolutionary work. ResNet enables training of up to hundreds or thousands of layers while maintaining impressive performance. The residual learning idea allows the neural network to extract more high-level properties from images and use them for classification with a lower error rate

Resnet50

Convolutional neural network ResNet-50 has 50 layers (48 convolutional layers, one MaxPool layer, and one average pool layer). On an ImageNet dataset, the ResNet50 model was initially trained.

# Implementation

# Testing

# Project Management

## Project Schedule

\newpage

## Risk Management

Project risk management is the process of locating, evaluating, and dealing with any risks that develop throughout the course of a project in order to keep it on track and achieve its objective. Being cautious in recognizing these risks and developing preventative actions is essential. The project's possible risks are shown in the table below, along with a preventive measure.

+------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------+
| **Risk**                     | **Mitigation**                                                                                                                                       | **Risk Severity** |
+:=============================+:=====================================================================================================================================================+:==================+
| Health Issue                 | Keep up a healthy sleep schedule and take medication if required.                                                                                    | Medium            |
+------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------+
|                              |                                                                                                                                                      |                   |
+------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------+
| Need of computing resources. | Reduce the size of the image because the dataset was so large, and try utilising Google Colab Pro and a high-performance computer at the university. | High              |
+------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------+
|                              |                                                                                                                                                      |                   |
+------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------+
| System failure               | Regular data backups to Github and external hard drives                                                                                              | High              |
+------------------------------+------------------------------------------------------------------------------------------------------------------------------------------------------+-------------------+

: Risk management

## Quality Management

## Social, Legal, Ethical and Professional Considerations

Throughout the project, every social, legal, ethical, and professional concern has been taken into account, and every effort has been made to ensure that none of them has been violated. Deep learning studies frequently raise social, legal, and ethical concerns because to the usage of datasets with sensitive data and the possibility for individual issues. The dataset used in this project was taken from the publicly accessible website and was utilised without raising any ethical or legal issues because it was intended for study and research purposes. If any information from other people's research is used in this report for any purpose, the appropriate sources are cited and given due credit.

# Critical Appraisal

\newpage

# Conclusions

Google Collaboratory is a service that allows users to run their Python code directly through their web browser using high-end Collaboratory hardware, taking use of cloud computing. Since we are using pre-trained models, completing our research by training each model separately will take a long time. Because of its tremendous computational capacity, Google Colaboratory Pro makes it much simpler and quicker to train the models.

In this study, the Keras API and TensorFlow library gave us all the tools we needed to successfully complete our deep learning experiment.

1\) **Metrics Evaluation:** We were able to determine metrics like as accuracy, precision, recall, and F1-Score Score, By making predictions on the test sets for all five models.

**Accuracy:** One of the popular evaluation metric is accuracy (see equation below). The total number of two right predictions (TP + TN) divided by the overall dataset size (P + N) is used to calculate accuracy. According to our evaluations, DenseNet201, VGG19, and EfficientNet V2L all have accuracy values of 61%, while ResNet50 has the greatest accuracy value of 63%.

$$
{ACC = \frac{TP +TN}{TP + TN + FN + FP} = \frac{TP + TN}{P + N}}
$$

**Precision and Recall:** Other commonly used evaluation metrics include precision and recall. Recall tells us about what portion of actual positives is correctly identified, while precision shows us clearly what percentage of projected positives is indeed a true positive.

$$
 {PREC = \frac{TP}{TP + FP}}
$$

$$
{RECALL = \frac{TP}{TP + FN}}
$$

**F1-Score:** The F1-score, which is the harmonic mean of Precision and Recall.

$$
{F1-SCORE = {\frac{(1 + \beta^2) (PREC \cdot REC)}{(\beta^2 \cdot PREC + REC)}}}
$$

Typically, beta is 0.5, 1, or 2.

## Achievements

## Future Work

In future studies, an extended data set can be used to design an algorithm that can give more successful and more stable results to test the detection rate of DR.

# Student Reflections

\newpage

# References

::: {#refs}
:::

\newpage

Appendix A -- Project Specification

Appendix B -- Interim Progress Report and Meeting Records

Appendix C -- Requirements Specification Document

Appendix D -- User Manual

Appendix E -- Project Presentation

Appendix F -- Certificate of Ethics Approval
